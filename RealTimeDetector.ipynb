{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RealTimeDetector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1lAfZbl-VTIicxZfU3lUO5D4yB1P6lR0N",
      "authorship_tag": "ABX9TyN35vf6yFqc9+sbpoAQNjbw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "liVZunFBEMSd"
      },
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "\n",
        "# Tensorflow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# openCV\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Uh27ZmYEzE7"
      },
      "source": [
        "# Colors to draw rectangles in BGR\n",
        "RED = (0,0,255)\n",
        "GREEN = (0,255,0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDMW_kcRE87K"
      },
      "source": [
        "# opencv object that will detect faces for us\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS5kw9quFNU3"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1jfScHzFLrY"
      },
      "source": [
        "# Load model to face classification\n",
        "# model was created in me_not_me_classifier\n",
        "model_name = 'face_classifier_ResNet152_aug.h5'\n",
        "face_classifier = keras.models.load_model(f'models/{model_name}')\n",
        "class_names = ['me','not_me']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0j2LgYMF_5L"
      },
      "source": [
        "def get_extended_image(img,x,y,w,h,k=0.1):\n",
        "  '''\n",
        "  Function, that return cropped image from 'img'\n",
        "  if k=0 returns image, cropped from (x, y)(top left) to (x+w, y+h)(bottom right)\n",
        "  if k!=0 returns image, cropped form (x-k*w, y-k*h) to (x+k*w, y+k*h)\n",
        "  after getting the desired image resize it to 250x250\n",
        "  and converts to tensor with shape(1,250,250,3)\n",
        "\n",
        "  Parameters:\n",
        "    img (array-like, 2D): The original image\n",
        "    x (int): x coordinate of the upper-left corner\n",
        "    y (int): y coordinate of the upper-left corner\n",
        "    w (int):  widht of desired image\n",
        "    h (int): height of desired image\n",
        "    k (float): the coefficient of expansion of the image\n",
        "  Returns:\n",
        "    image(tensor with shape(1,250,250,3))\n",
        "  '''\n",
        "  # The next code block checks that coordinates will be non-negative\n",
        "  # (in case if desired image is located in top left corner)\n",
        "  if x-k*w>0:\n",
        "    start_x = int(x-k*w)\n",
        "  else:\n",
        "    start_x=x\n",
        "  if y-k*h>0:\n",
        "    start_y = int(y-k*h)\n",
        "  else:\n",
        "    start_y = y\n",
        "\n",
        "  end_x = int(x+(1+k)*w)\n",
        "  end_y = int(y+(1+k)*h)\n",
        "\n",
        "  face_image = img[start_y:end_y,start_x:end_x]\n",
        "  face_image = tf.image.resize(face_image,[250,250])\n",
        "  # shape form (250,250) to (1,250,250,3)\n",
        "  face_image = np.expand_dims(face_image,axis=0)\n",
        "  return face_image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIu2NhAOIelU"
      },
      "source": [
        "Straming Cycle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxWl3QtsIeQi"
      },
      "source": [
        "video_capture = cv2.VideoCapture(0) #webcamera\n",
        "\n",
        "if not video_capture.isOpened():\n",
        "  print(\"Unable to access the camera\")\n",
        "else:\n",
        "  print(\"Access to camera was successfully obtained\")\n",
        "\n",
        "print(\"Sreaming stated - to quit press ESC\")\n",
        "\n",
        "while True:\n",
        "  # capture frame-by-frame\n",
        "  ret,frame = video_capture.read()\n",
        "  if not ret:\n",
        "    print(\"Can't receive frame (steam end?). Exiting........\")\n",
        "    break\n",
        "  gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  faces = face_cascade.detectMultiScale(\n",
        "      gray,\n",
        "      scaleFactor=1.3,\n",
        "      minNeighbors=5,\n",
        "      minSize=(100,100),\n",
        "      flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "  \n",
        "  for (x,y,w,h) in faces:\n",
        "    # for each face on the image detected by OpenCV\n",
        "    # get extended image of this face\n",
        "    face_image = get_extended_image(frame,x,y,w,h,0.5)\n",
        "\n",
        "    # Classify face and draw a rectangle around the face\n",
        "    # green for +ve class and red for -ve\n",
        "    result = face_classifier.predict(face_image)\n",
        "    prediction = class_names[np.array(\n",
        "        result[0]).argmax(axis=0)] #predicted class\n",
        "    confidence = np.array(result[0]).max(axis=0) #degree of confidence\n",
        "\n",
        "    if prediction == 'me':\n",
        "      color=GREEN\n",
        "    else:\n",
        "      color=RED\n",
        "    \n",
        "    # Draw rectangle around the face\n",
        "    cv2.rectangle(frame,\n",
        "                  (x,y),    #start_point\n",
        "                  (x+w,y+h),    #end_point\n",
        "                  color,\n",
        "                  2)    #thickness in px\n",
        "    cv2.putText(frame,\n",
        "                # text to put\n",
        "                \"{:6} - {:.2f}%\".format(prediction,confidence*100),\n",
        "                (x,y),\n",
        "                cv2.FONT_HERSHEY_PLAIN,   #font\n",
        "                2, #font scale\n",
        "                color,\n",
        "                2)    #thickness in px\n",
        "    # display the resulting frame\n",
        "    cv2.imshow(\"face detector - to quit press ESC\",frame)\n",
        "    # exit with ESC\n",
        "    key=cv2.waitKey(1)\n",
        "    if key%256==27:   #ESC code\n",
        "      break\n",
        "\n",
        "# When everythin done, release the capture\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(\"Steaming Ended\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}